{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiVfKn-6tXz8"
   },
   "source": [
    "# **Homework 8 - Anomaly Detection**\n",
    "\n",
    "If there are any questions, please contact mlta-2022spring-ta@googlegroups.com\n",
    "\n",
    "Slide:    [Link]()　Kaggle: [Link](https://www.kaggle.com/c/ml2022spring-hw8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDk9r2YOcDc9"
   },
   "source": [
    "# Set up the environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oi12tJMYWi0Q"
   },
   "source": [
    "## Package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LexxyPWWjJB",
    "outputId": "3a733a84-fca3-4e7c-fb9b-bfd5f890114d"
   },
   "outputs": [],
   "source": [
    "# Training progress bar\n",
    "%pip install -q qqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCgNXSsEWuY7"
   },
   "source": [
    "## Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SCLJtgF2BLSK",
    "outputId": "54d462c4-2121-46a9-a966-1ca9b01e7b61"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/MachineLearningHW/HW8_Dataset/releases/download/v1.0.0/data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0K5kmlkuWzhJ",
    "outputId": "c12176a4-f513-4ed3-c351-c82ef26e8072"
   },
   "outputs": [],
   "source": [
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNe7QU7n7cqh"
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jk3qFK_a7k8P"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "from torch.optim import Adam, AdamW, lr_scheduler\n",
    "from qqdm import qqdm, format_str\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6X6fkGPnYyaF"
   },
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k7Wd4yiUYzAm",
    "outputId": "2c2fa7bf-1c0a-4090-ac16-627c1fe5ca5c"
   },
   "outputs": [],
   "source": [
    "train = np.load('data/trainingset.npy', allow_pickle=True)\n",
    "test = np.load('data/testingset.npy', allow_pickle=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_flpmj6OYIa6"
   },
   "source": [
    "## Random seed\n",
    "Set the random seed to a certain value for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gb-dgXQYYI2Q"
   },
   "outputs": [],
   "source": [
    "def same_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "same_seeds(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zR9zC0_Df-CR"
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EbfwRREhA7c"
   },
   "source": [
    "# Models & loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wi8ds1fugCkR"
   },
   "outputs": [],
   "source": [
    "class fcn_autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fcn_autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(64 * 64 * 3, 1024),\n",
    "            nn.LeakyReLU(0.1), \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.1), \n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, 128), \n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128, 64),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(1024, 64 * 64 * 3), \n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        code = self.encoder(x)\n",
    "        # Adjust Latent Repr for Report Image\n",
    "        # code = target_code\n",
    "        y = self.decoder(code)\n",
    "        # return code, y\n",
    "        return y\n",
    "\n",
    "\n",
    "class conv_autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(conv_autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),  \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 3, 4, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, 4, stride=2, padding=1),            \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(12, 24, 4, stride=2, padding=1),    \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.enc_out_1 = nn.Sequential(\n",
    "            nn.Conv2d(24, 48, 4, stride=2, padding=1),  \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.enc_out_2 = nn.Sequential(\n",
    "            nn.Conv2d(24, 48, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1), \n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = self.encoder(x)\n",
    "        return self.enc_out_1(h1), self.enc_out_2(h1)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "\n",
    "def loss_vae(recon_x, x, mu, logvar, criterion):\n",
    "    \"\"\"\n",
    "    recon_x: generating images\n",
    "    x: origin images\n",
    "    mu: latent mean\n",
    "    logvar: latent log variance\n",
    "    \"\"\"\n",
    "    mse = criterion(recon_x, x)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    return mse + KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrJ9bScg9AgO"
   },
   "source": [
    "# Dataset module\n",
    "\n",
    "Module for obtaining and processing data. The transform function here normalizes image's pixels from [0, 255] to [-1.0, 1.0].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33fWhE-h9LPq"
   },
   "outputs": [],
   "source": [
    "class CustomTensorDataset(TensorDataset):\n",
    "    \"\"\"TensorDataset with support of transforms.\n",
    "    \"\"\"\n",
    "    def __init__(self, tensors):\n",
    "        self.tensors = tensors\n",
    "        if tensors.shape[-1] == 3:\n",
    "            self.tensors = tensors.permute(0, 3, 1, 2)\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "          transforms.Lambda(lambda x: x.to(torch.float32)),\n",
    "          transforms.Lambda(lambda x: 2. * x/255. - 1.),\n",
    "        ])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.tensors[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            # mapping images to [-1.0, 1.0]\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKNUImqUhIeq"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ebAJdjFmS08"
   },
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "in7yLfmqtZTk"
   },
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "num_epochs = 200 # 500 \n",
    "batch_size = 256\n",
    "learning_rate = 5e-4 # 1e-3\n",
    "\n",
    "# Build training dataloader\n",
    "x = torch.from_numpy(train)\n",
    "train_dataset = CustomTensorDataset(x)\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Model\n",
    "model_type = 'fcn'   # selecting a model type from {'cnn', 'fcn', 'vae', 'resnet'}\n",
    "model_classes = {'fcn': fcn_autoencoder(), 'cnn': conv_autoencoder(), 'vae': VAE()}\n",
    "model = model_classes[model_type].cuda()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "break_steps = int(0.05 * total_steps)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=break_steps, gamma=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyooN-JPm8sS"
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoW1UrrxgI_U"
   },
   "outputs": [],
   "source": [
    "best_loss = np.inf\n",
    "model.train()\n",
    "\n",
    "qqdm_train = qqdm(range(num_epochs), desc=format_str('bold', 'Description'))\n",
    "for epoch in qqdm_train:\n",
    "    tot_loss = list()\n",
    "    for data in train_dataloader:\n",
    "\n",
    "        # ===================loading=====================\n",
    "        img = data.float().cuda()\n",
    "        if model_type in ['fcn']:\n",
    "            img = img.view(img.shape[0], -1)\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        if model_type in ['vae']:\n",
    "            loss = loss_vae(output[0], img, output[1], output[2], criterion)\n",
    "        else:\n",
    "            loss = criterion(output, img)\n",
    "\n",
    "        tot_loss.append(loss.item())\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    # ===================save_best====================\n",
    "    mean_loss = np.mean(tot_loss)\n",
    "    if mean_loss < best_loss:\n",
    "        best_loss = mean_loss\n",
    "        torch.save(model, './models/best_model_{}.pt'.format(model_type))\n",
    "    # ===================log========================\n",
    "    qqdm_train.set_infos({\n",
    "        'epoch': f'{epoch + 1:.0f}/{num_epochs:.0f}',\n",
    "        'loss': f'{mean_loss:.4f}',\n",
    "    })\n",
    "    # ===================save_last========================\n",
    "    torch.save(model, './models/last_model_{}.pt'.format(model_type))\n",
    "    print(f\"LR: {scheduler.get_last_lr()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust latent representation and plot its result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"./models/report_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = fcn_autoencoder()\n",
    "# model = model.cuda()\n",
    "# model.load_state_dict(torch.load(\"./models/report_model\"))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_batch_size = 1\n",
    "\n",
    "# # build testing dataloader\n",
    "# data = torch.tensor(test, dtype=torch.float32)\n",
    "# test_dataset = CustomTensorDataset(data)\n",
    "# test_sampler = SequentialSampler(test_dataset)\n",
    "# test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=eval_batch_size, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %pip install opencv-python\n",
    "# import torchvision\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# anomality = list()\n",
    "# with torch.no_grad():\n",
    "#     for i, data in enumerate(test_dataloader):\n",
    "#         if i == 9:\n",
    "#             ######### 原始圖片 #########\n",
    "#             print(\"原始圖片\")\n",
    "#             img = data.float()\n",
    "#             img = img.squeeze(0)\n",
    "#             print(img.shape)\n",
    "#             img = img.permute(1, 2, 0).numpy()\n",
    "#             plt.imshow(img)\n",
    "#             plt.show()\n",
    "#             ###### Latent Repr. #######\n",
    "#             img_train = data.float().cuda()\n",
    "#             img_train = img_train.view(img_train.shape[0], -1)\n",
    "#             target_code, output = model(img_train)\n",
    "#             ######### 原始輸出 #########\n",
    "#             print(\"原始輸出\")\n",
    "#             print(output.shape)\n",
    "#             output = output.squeeze(0).cpu()\n",
    "#             output = output.reshape((3, 64, 64))\n",
    "#             print(output.shape)\n",
    "#             output = output.permute(1, 2, 0).numpy()\n",
    "#             plt.imshow(output)\n",
    "#             plt.show()\n",
    "#             ## Adjust Latent Repr. ###\n",
    "#             print(\"Code 調整\")\n",
    "#             print(target_code)\n",
    "#             target_code[0][-1] += 20\n",
    "#             print(target_code)\n",
    "#             ###########################\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %pip install opencv-python\n",
    "# import torchvision\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# anomality = list()\n",
    "# with torch.no_grad():\n",
    "#     for i, data in enumerate(test_dataloader):\n",
    "#         if i == 9:\n",
    "#             ######### 原始圖片 #########\n",
    "#             print(\"原始圖片\")\n",
    "#             img = data.float()\n",
    "#             img = img.squeeze(0)\n",
    "#             print(img.shape)\n",
    "#             img = img.permute(1, 2, 0).numpy()\n",
    "#             plt.imshow(img)\n",
    "#             plt.show()\n",
    "#             ###### Latent Repr. #######\n",
    "#             img_train = data.float().cuda()\n",
    "#             img_train = img_train.view(img_train.shape[0], -1)\n",
    "#             target_code, output = model(img_train)\n",
    "#             ######### 調整後輸出 #########\n",
    "#             print(\"調整後輸出\")\n",
    "#             print(output.shape)\n",
    "#             output = output.squeeze(0).cpu()\n",
    "#             output = output.reshape((3, 64, 64))\n",
    "#             print(output.shape)\n",
    "#             output = output.permute(1, 2, 0).numpy()\n",
    "#             plt.imshow(output)\n",
    "#             plt.show()\n",
    "#             ###########################\n",
    "#             break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wk0UxFuchLzR"
   },
   "source": [
    "# Inference\n",
    "Model is loaded and generates its anomaly score predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evgMW3OwoGqD"
   },
   "source": [
    "## Initialize\n",
    "- dataloader\n",
    "- model\n",
    "- prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_MBnXAswoKmq"
   },
   "outputs": [],
   "source": [
    "eval_batch_size = 200\n",
    "\n",
    "# build testing dataloader\n",
    "data = torch.tensor(test, dtype=torch.float32)\n",
    "test_dataset = CustomTensorDataset(data)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=eval_batch_size, num_workers=1)\n",
    "eval_loss = nn.MSELoss(reduction='none')\n",
    "\n",
    "# load trained model\n",
    "checkpoint_path = f'./models/best_model_{model_type}.pt'\n",
    "model = torch.load(checkpoint_path)\n",
    "model.eval()\n",
    "\n",
    "# prediction file \n",
    "out_file = './outputs/prediction.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1IxCX2iCW6V"
   },
   "outputs": [],
   "source": [
    "anomality = list()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        img = data.float().cuda()\n",
    "        if model_type in ['fcn']:\n",
    "            img = img.view(img.shape[0], -1)\n",
    "        output = model(img)\n",
    "        if model_type in ['vae']:\n",
    "            output = output[0]\n",
    "        if model_type in ['fcn']:\n",
    "            loss = eval_loss(output, img).sum(-1)\n",
    "        else:\n",
    "            loss = eval_loss(output, img).sum([1, 2, 3])\n",
    "        anomality.append(loss)\n",
    "anomality = torch.cat(anomality, axis=0)\n",
    "anomality = torch.sqrt(anomality).reshape(len(test), 1).cpu().numpy()\n",
    "\n",
    "df = pd.DataFrame(anomality, columns=['score'])\n",
    "df.to_csv(out_file, index_label = 'ID')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "bDk9r2YOcDc9",
    "Oi12tJMYWi0Q",
    "DCgNXSsEWuY7",
    "HNe7QU7n7cqh",
    "6X6fkGPnYyaF",
    "1EbfwRREhA7c",
    "vrJ9bScg9AgO",
    "XKNUImqUhIeq"
   ],
   "name": "ML2022Spring - HW8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "kuokuo_env",
   "language": "python",
   "name": "kuokuo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
